{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob, re\n",
    "import pprint as pp\n",
    "from rake_nltk import Metric, Rake\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class Talat:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ):\n",
    "\n",
    "    \tself.all_terms = None\n",
    "\n",
    "    def setAllTerms(self,all_terms):\n",
    "        self.all_terms = all_terms\n",
    "\n",
    "    def runExtractionArticle(self,res,text):\n",
    "\n",
    "        global morph_dic\n",
    "        grammaire = [\"ainsi\",\"ces\",\"ce\", \"ceux\", \"celles\", \"cet\", \"cette\", \"aucun\",\"un\", \"une\", \"les\", \"pour\", \"par\", \"dans\", \"vers\", \"pendant\", \"depuis\" , \"malgé\", \"comme\", \"contre\", \"ci\", \"selon\", \"parce\", \"grâce\", \"surtout\", \"afin\", \"tel\", \"telles\", \"tels\", \"telle\"]\n",
    "\n",
    "        ending_grammaire = [\"du\", \"des\", \"de\"]\n",
    "\n",
    "        def isGrammar(word):\n",
    "            if word in morph_dic[\"adjectif\"]:\n",
    "                return False\n",
    "            if word in morph_dic[\"grammaire\"]:\n",
    "                return True\n",
    "\n",
    "        mots_outils = stopwords.words(\"french\")\n",
    "        ponctuation = string.punctuation\n",
    "        r = Rake(language = 'fr', punctuations = ponctuation, stopwords = mots_outils)\n",
    "        r.extract_keywords_from_text(text)\n",
    "\n",
    "        for index, candidate in enumerate(r.get_ranked_phrases_with_scores()):\n",
    "            new_candidate = candidate[1]\n",
    "            good_candidate = True\n",
    "\n",
    "            if len(candidate[1].split(' '))<2:\n",
    "                good_candidate = False\n",
    "\n",
    "            i=0\n",
    "            for w in candidate[1].split(' '):\n",
    "\n",
    "                if i==0 and (w in morph_dic[\"adverbe\"] or w in morph_dic[\"adjectif\"]):\n",
    "                    good_candidate = False\n",
    "                    break\n",
    "\n",
    "                if i==(len(candidate[1].split(' '))-1) and (w in ending_grammaire):\n",
    "                    good_candidate = False\n",
    "                    break\n",
    "\n",
    "                if isGrammar(w):\n",
    "                    good_candidate = False\n",
    "                    break\n",
    "\n",
    "                if w in grammaire:\n",
    "                    good_candidate = False\n",
    "                    break\n",
    "\n",
    "                if (w in string.punctuation or (w in [\"\\uf0b7\",\"▪\",\"’\",\"«\", \"»\", \"»\", \"»\"])):\n",
    "                    new_candidate = new_candidate.replace(w,\"\")\n",
    "                    continue\n",
    "\n",
    "                for p in string.punctuation:\n",
    "                    if p in w:\n",
    "                        new_candidate = new_candidate.replace(p,\"\")\n",
    "\n",
    "                i+=1\n",
    "\n",
    "            if good_candidate:\n",
    "                res[new_candidate.strip()] = ''\n",
    "\n",
    "        return res\n",
    "\n",
    "    def extractTermsArticle(self,article, dic):\n",
    "    \tprint(\"treating article with length \" + str(len(article)))\n",
    "\n",
    "    \tfor kw in self.all_terms:\n",
    "    \t\tif kw in article:\n",
    "    \t\t\tdic.setdefault(kw,0)\n",
    "    \t\t\tdic[kw] += article.count(kw)\n",
    "\n",
    "    \treturn dic\n",
    "\n",
    "    def countOccurenceCorpus(self,corpus):\n",
    "    \tall_terms_freq = {}\n",
    "\n",
    "    \tfor filename in sorted(glob.glob(corpus)):\n",
    "    \t\tprint(\"\\n\"+filename)\n",
    "    \t\tfile = open(filename)\n",
    "    \t\tcurr_article = file.read().lower()\n",
    "\n",
    "    \t\tfor kw in self.all_terms:\n",
    "    \t\t\tall_terms_freq.setdefault(kw,0)\n",
    "    \t\t\tall_terms_freq[kw] += curr_article.count(kw)\n",
    "\n",
    "    \t\tfile.close()\n",
    "\n",
    "    \treturn all_terms_freq\n",
    "\n",
    "    def countOccurenceYear(self,corpus):\n",
    "\n",
    "    \tyear_terms_freq = {}\n",
    "\n",
    "    \tfor filename in sorted(glob.glob(corpus)):\n",
    "    \t\tprint(filename)\n",
    "    \t\tyear = filename.split('-')[1]\n",
    "    \t\tfile = open(filename)\n",
    "    \t\tarticle = file.read().lower()\n",
    "    \t\tyear_terms_freq.setdefault(year,{})\n",
    "\n",
    "    \t\tfor kw in self.all_terms:\n",
    "    \t\t\tyear_terms_freq[year].setdefault(kw,0)\n",
    "    \t\t\tyear_terms_freq[year][kw] += article.count(kw)\n",
    "    \t\t\n",
    "    \t\tfile.close()\n",
    "\n",
    "    \treturn year_terms_freq\n",
    "\n",
    "    def growth_rate(self,freq_voc1,freq_voc2):\n",
    "        growth_dic = {}\n",
    "        for w in freq_voc1:\n",
    "            print(w)\n",
    "            if freq_voc1[w] != 0:\n",
    "                growth_dic[w] = freq_voc2[w] / freq_voc1[w]\n",
    "                continue\n",
    "            if freq_voc2[w] == 0:\n",
    "                growth_dic[w] = 0\n",
    "                continue\n",
    "            if freq_voc2[w] > 0 and freq_voc1[w] == 0:\n",
    "                growth_dic[w] = 100000\n",
    "                continue\n",
    "\n",
    "\n",
    "        return growth_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8373a",
   "metadata": {},
   "source": [
    "# INITIALISATION DE TALAT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open('talatlogo.txt').read())\n",
    "global morph_dic\n",
    "with open('morph_dic.json') as outfile:\n",
    "    morph_dic = json.load(outfile)\n",
    "\n",
    "talat = Talat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048e5cb",
   "metadata": {},
   "source": [
    "# extraction d'unités terminologiques polylexicales :\n",
    "## iteration sur le corpus et extraction des termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afccf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for filename in sorted(glob.glob(\"corpus/corpusLQ/*\")):\n",
    "    print(\"\\n\"+filename)\n",
    "    file = open(filename)\n",
    "    curr_article = file.read().lower()\n",
    "    res = talat.runExtractionArticle(res,curr_article)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "with open(\"termes.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(res, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "pp.pprint(res)\n",
    "talat.setAllTerms(res) #attribut une liste de termes pour talat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089af5a4",
   "metadata": {},
   "source": [
    "# Calcule du growth rate pour chaque terme sur une fenêtre par année :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51274982",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_years_dic = talat.countOccurenceYear('corpus/corpusLQ/*')\n",
    "\n",
    "\n",
    "with open(\"occ_years_dic .json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(occ_years_dic, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "with open('occ_years_dic.json') as outfile:\n",
    "    occ_years_dic = json.load(outfile)\n",
    "\n",
    "growth_dic_years = {}\n",
    "for year in range(2007,2013):\n",
    "    year = str(year)\n",
    "    if year == \"2013\":\n",
    "        break\n",
    "    print(year)\n",
    "    growth_dic_years[year + \" \" + str(int(year)+1)] =  talat.growth_rate(occ_years_dic[year], occ_years_dic[str(int(year)+1)])\n",
    "\n",
    "\n",
    "with open(\"growth_dic_years.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(growth_dic_years, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('growth_dic_years.json') as outfile:\n",
    "    growth_dic_years = json.load(outfile)\n",
    "\n",
    "with open('termes.json') as outfile:\n",
    "    termes = json.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4dd94",
   "metadata": {},
   "source": [
    "# nouvelle représentation du growth rate ; en fonction des termes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_gr_years = {}\n",
    "\n",
    "for t in termes:\n",
    "    print(t)\n",
    "    termes_gr_years[t] = {}\n",
    "    for gr_years in growth_dic_years:\n",
    "        termes_gr_years[t][gr_years] = growth_dic_years[gr_years][t]\n",
    "\n",
    "with open(\"termes_gr_years.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(termes_gr_years, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('termes_gr_years.json') as outfile:\n",
    "    termes_gr_years = json.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7684995",
   "metadata": {},
   "source": [
    "# extraction des termes qui apparaissent puis ont une fréquence stable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbd67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging_concepts = {}\n",
    "for t in termes_gr_years:\n",
    "    rates = []\n",
    "    for year_pairs in termes_gr_years[t]:\n",
    "        rates.append(termes_gr_years[t][year_pairs])\n",
    "\n",
    "    b = False\n",
    "    if rates.count(100000) == 1 and all_terms_freq[t] > 20:\n",
    "        b = True\n",
    "        index = rates.index(100000)\n",
    "        for gr in rates[index:]:\n",
    "            if gr == 0:\n",
    "                b = False\n",
    "        for gr in rates[:index]:\n",
    "            if gr > 0:\n",
    "                b = False\n",
    "\n",
    "    if b == True:\n",
    "        emerging_concepts[t] = termes_gr_years[t]\n",
    "\n",
    "  \n",
    "pp.pprint(emerging_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129cbe6",
   "metadata": {},
   "source": [
    "# Récupération des termes sur un seul article pour évalutation du système Talat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89dc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_article = open(\"corpusTAL/corpus/recital-2007-long-001\").read()\n",
    "test_article_kw = talat.extractTermsArticle(curr_article)\n",
    "\n",
    "missing1 = []\n",
    "for kw in test_article_kw:\n",
    "\tif kw not in corp_ref:\n",
    "\t\tmissing1.append(kw)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Evalutation TALAT sur corpus de ref: \"+ str(len(missing1)/len(corp_ref)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263068b",
   "metadata": {},
   "source": [
    "# Statistiques fréquences sur corpus entier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms_freq = talat.countOccurenceCorpus(\"corpusTAL/corpus/*\")\n",
    "pp.pprint(sorted(all_terms_freq.items(), key = lambda item : item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ca043",
   "metadata": {},
   "source": [
    "# statistiques corpus fréquence par années :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_freq =  talat.countOccurenceYear(\"corpusTAL/corpus/*\")\n",
    "\n",
    "with open(\"years_terms_freq.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(year_freq, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "pp.pprint(year_freq)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('years_terms_freq2.json') as outfile:\n",
    "    year_freq_new = json.load(outfile)\n",
    "\n",
    "\n",
    "year_freq_new ={}\n",
    "for year in year_freq:\n",
    "\tyear_freq_new.setdefault(year,{})\n",
    "\tfor kw in year_freq[year]:\n",
    "\t\tif year_freq[year][kw] >= 2:\n",
    "\t\t\tyear_freq_new[year][kw] = year_freq[year][kw]\n",
    "\t\t\t\n",
    "\n",
    "with open(\"years_terms_freq2.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(year_freq_new, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "for year in year_freq_new:\n",
    "\tprint(year)\n",
    "\tpp.pprint(sorted(year_freq_new[year].items(), key = lambda item : item[1]))\n",
    "\n",
    "\n",
    "gr_07_08 = talat.growth_rate(year_freq_new[\"2007\"],year_freq_new[\"2008\"])\n",
    "pp.pprint(sorted(gr_07_08.items(), key = lambda item : item[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kw_detected_articles = {}\n",
    "for filename in sorted(glob.glob('corpusTAL/corpus/*')):\n",
    "\tprint(\"\\n\"+filename)\n",
    "\tcurr_article = open(filename).read()\n",
    "\n",
    "\tkw_detected_articles[filename] = talat.extractTermsArticle(curr_article)\n",
    "\tbreak\n",
    "\n",
    "print(kw_detected_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
